{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV Version: 3.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras image data format: channels_last\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import os \n",
    "import time \n",
    "import uuid \n",
    "import math \n",
    "from IPython.display import display as ipydisplay, Image, clear_output, HTML \n",
    "\n",
    "import numpy as np \n",
    "import cv2 \n",
    "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "print('OpenCV Version: {}.{}.{}'.format(major_ver, minor_ver, subminor_ver))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras \n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "print('Keras image data format: {}'.format(K.image_data_format()))\n",
    "from sound import Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hand_model = load_model('1234.hdf5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = {\n",
    "    0: '1',\n",
    "    1: '2',\n",
    "    2: '3',\n",
    "    3: '4'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def mask_array(array, imask):\n",
    "    if array.shape[:2] != imask.shape:\n",
    "        raise Exception(\"Shapes of input and imask are incompatible\")\n",
    "    output = np.zeros_like(array, dtype=np.uint8)\n",
    "    for i, row in enumerate(imask):\n",
    "        output[i, row] = array[i, row]\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "if not video.isOpened():\n",
    "    print(\"Could not open video\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "\n",
    "ok, frame = video.read()\n",
    "if not ok:\n",
    "    print(\"Cannot read video\")\n",
    "    sys.exit()\n",
    "\n",
    "bg = frame.copy()\n",
    "\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "positions = {\n",
    "    'hand_pose': (15, 40), \n",
    "    'fps': (15, 20), \n",
    "    'null_pos': (200, 200) \n",
    "}\n",
    "\n",
    "\n",
    "bbox_initial = (116, 116, 170, 170) \n",
    "bbox = bbox_initial\n",
    "\n",
    "tracking = -1\n",
    "  \n",
    "while True:\n",
    "    \n",
    "    ok, frame = video.read()\n",
    "    display = frame.copy()\n",
    "    data_display = np.zeros_like(display, dtype=np.uint8) \n",
    "    if not ok:\n",
    "        break\n",
    "        \n",
    "     \n",
    "    timer = cv2.getTickCount()\n",
    "\n",
    "    \n",
    "    diff = cv2.absdiff(bg, frame)\n",
    "    mask = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    th, thresh = cv2.threshold(mask, 10, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    img_dilation = cv2.dilate(closing, kernel, iterations=2)\n",
    "    \n",
    "    imask = img_dilation > 0\n",
    "    \n",
    "    foreground = mask_array(frame, imask)\n",
    "    foreground_display = foreground.copy()\n",
    "    \n",
    "    \n",
    "    if tracking != -1:\n",
    "        tracking, bbox = tracker.update(foreground)\n",
    "        tracking = int(tracking)\n",
    "        \n",
    "   \n",
    "    hand_crop = img_dilation[int(bbox[1]):int(bbox[1]+bbox[3]), int(bbox[0]):int(bbox[0]+bbox[2])]\n",
    "    try:\n",
    "        \n",
    "        hand_crop_resized = np.expand_dims(cv2.resize(hand_crop, (54, 54)), axis=0).reshape((1, 54, 54, 1))\n",
    "        prediction = hand_model.predict(hand_crop_resized)\n",
    "        predi = prediction[0].argmax() \n",
    "        gesture = classes[predi]\n",
    "        \n",
    "        for i, pred in enumerate(prediction[0]):\n",
    "            \n",
    "            barx = positions['hand_pose'][0]\n",
    "            bary = 60 + i*60\n",
    "            bar_height = 20\n",
    "            bar_length = int(400 * pred) + barx\n",
    "            print(gesture)\n",
    "            if (gesture == \"2\"):\n",
    "                Sound.volume_down()\n",
    "               \n",
    "\n",
    "            elif (gesture == \"4\"):\n",
    "                Sound.volume_up()\n",
    "                \n",
    "            \n",
    "            if i == predi:\n",
    "                colour = (0, 255, 0)\n",
    "            else:\n",
    "                colour = (0, 0, 255)\n",
    "            \n",
    "            cv2.putText(data_display, \"{}: {}\".format(classes[i], pred), (positions['hand_pose'][0], 30 + i*60), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)\n",
    "            cv2.rectangle(data_display, (barx, bary), (bar_length, bary - bar_height), colour, -1, 1)\n",
    "        \n",
    "        cv2.putText(display, \"hand pose: {}\".format(gesture), positions['hand_pose'], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        cv2.putText(foreground_display, \"hand pose: {}\".format(gesture), positions['hand_pose'], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "    except Exception as ex:\n",
    "        cv2.putText(display, \"hand pose: error\", positions['hand_pose'], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        cv2.putText(foreground_display, \"hand pose: error\", positions['hand_pose'], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "    \n",
    "    \n",
    "    p1 = (int(bbox[0]), int(bbox[1]))\n",
    "    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "    cv2.rectangle(foreground_display, p1, p2, (255, 0, 0), 2, 1)\n",
    "    cv2.rectangle(display, p1, p2, (255, 0, 0), 2, 1)\n",
    "    \n",
    "    \n",
    "    hand_pos = ((p1[0] + p2[0])//2, (p1[1] + p2[1])//2)\n",
    "    mouse_change = ((p1[0] + p2[0])//2 - positions['null_pos'][0], positions['null_pos'][0] - (p1[1] + p2[1])//2)\n",
    "    \n",
    "    cv2.circle(display, positions['null_pos'], 5, (0,0,255), -1)\n",
    "    cv2.circle(display, hand_pos, 5, (0,255,0), -1)\n",
    "    cv2.line(display,positions['null_pos'],hand_pos,(255,0,0),5)\n",
    "    \n",
    "     \n",
    "    fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)\n",
    "    \n",
    "    cv2.putText(foreground_display, \"FPS : \" + str(int(fps)), positions['fps'], cv2.FONT_HERSHEY_SIMPLEX, 0.65, (50, 170, 50), 2)\n",
    "    cv2.putText(display, \"FPS : \" + str(int(fps)), positions['fps'], cv2.FONT_HERSHEY_SIMPLEX, 0.65, (50, 170, 50), 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"display\", display)\n",
    "   \n",
    "    cv2.imshow(\"data\", data_display)\n",
    "   \n",
    "    cv2.imshow(\"diff\", diff)\n",
    "   \n",
    "    cv2.imshow(\"thresh\", thresh)\n",
    "    \n",
    "    cv2.imshow(\"img_dilation\", img_dilation)\n",
    "    try:\n",
    "       \n",
    "        cv2.imshow(\"hand_crop\", hand_crop)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    cv2.imshow(\"foreground_display\", foreground_display)\n",
    "    \n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    \n",
    "    if k == 27: break # ESC pressed\n",
    "    elif k == 114 or k == 108: \n",
    "       \n",
    "        bg = frame.copy()\n",
    "        bbox = bbox_initial\n",
    "        tracking = -1\n",
    "    elif k == 116:\n",
    "       \n",
    "        tracker = setup_tracker(2)\n",
    "        tracking = tracker.init(frame, bbox)\n",
    "    elif k == 115:\n",
    "        \n",
    "        fname = os.path.join(\"data\", CURR_POS, \"{}_{}.jpg\".format(CURR_POS, get_unique_name(os.path.join(\"data\", CURR_POS))))\n",
    "        cv2.imwrite(fname, hand_crop)\n",
    "    elif k != 255: print(k)\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
